datCredit_valid[(is.na(ClusVar_Def)),.N]
datGraph_Perf[is.na(ClusVar_Perf),.N]
datGraph_Perf[is.na(ClusVar_Def),.N]
# - Setting some aggregation parameters, purely to facilitate graphing aesthetics
StartDte <- min(datCredit_smp$timeVar, na.rm=T)
EndDte <- max(datCredit_smp$timeVar, na.rm=T)
maxDate <- EndDte # A post-hoc filter, used for graphing purposes - left as the end of the sampling window
minDate <- StartDte %m+% months(1) # A post-hoc filter, used for graphing purposes - set as one month after the sampling window
# - Aggregate to monthly level and observe up to given point
port.aggr_perf <- merge(datGraph_Perf[timeVar==timeVar_Perf_Min, list(Sum_Total = .N), by=list(Sample,timeVar)],
datGraph_Perf[timeVar==timeVar_Perf_Min, list(Sum_Resol = .N), by=list(Sample,timeVar,PerfSpell_Resol)],
by=c("Sample", "timeVar"))[timeVar >= minDate & timeVar <= maxDate,]
port.aggr_perf[, Prop := Sum_Resol/Sum_Total]
# - Calculate MAE over time by sample, by performance event(s)
port.aggr_perf2 <- port.aggr_perf %>% pivot_wider(id_cols = c(timeVar), names_from = c(Sample, PerfSpell_Resol), values_from = Prop) %>% data.table()
# - Get the unique factors of the performance spell resolution type (used as facets)
resolPerf_levels <- unique(datCredit[!is.na(get(resolPerf)), get(resolPerf)])
# - Number of annotations "sets" to create
anno_n <- length(resolPerf_levels)
# - Initiating the annotation dataset
x_pos <- min(datCredit$timeVar) + round((max(datCredit$timeVar) - min(datCredit$timeVar))/2) # x-position fot the annotation
dat_anno_perf <- data.table(MAE = rep(0,anno_n*3),
Mean_EventRate = rep(0, anno_n*3),
stdError_EventRate = rep(0, anno_n*3),
margin_EventRate = rep(0, anno_n*3),
PerfSpell_Resol = unlist(lapply(resolPerf_levels, function(x){rep(x,3)})),
Dataset = rep(c("A-B","A-C","B-C"), anno_n),
Label = rep(c(paste0("'MAE between '*italic(A[t])*' and '*italic(B[t])*'"),
paste0("'MAE between '*italic(A[t])*' and '*italic(C[t])*'"),
paste0("'MAE between '*italic(B[t])*' and '*italic(C[t])*'")),
anno_n),
x = rep(x_pos,anno_n*3),
y = rep(Inf, anno_n*4), # c(c(0.9,0.83,0.76),c(0.6,0.55,0.5),c(0.9,0.83,0.76)),
vjust = rep(c(1,2,3, 4), anno_n),
hjust=rep(0.5, anno_n*3))
# - Getting the column names to help compute the MAEs
colnames <- colnames(port.aggr_perf2)
# - Populating the annotation dataset
for (i in 1:anno_n){
dat_anno_perf[i*3-2, MAE := mean(abs(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("a_Full_", resolPerf_levels[i])])[[1]] - subset(port.aggr_perf2, select=colnames[colnames %in% paste0("b_Train_", resolPerf_levels[i])])[[1]]), na.rm = T)] # MAE between the full- and training dataset
dat_anno_perf[i*3-1, MAE := mean(abs(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("a_Full_", resolPerf_levels[i])])[[1]] - subset(port.aggr_perf2, select=colnames[colnames %in% paste0("c_Valid_", resolPerf_levels[i])])[[1]]), na.rm = T)] # MAE between the full- and validation dataset
dat_anno_perf[i*3, MAE := mean(abs(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("b_Train_", resolPerf_levels[i])])[[1]] - subset(port.aggr_perf2, select=colnames[colnames %in% paste0("c_Valid_", resolPerf_levels[i])])[[1]]), na.rm = T)] # MAE between the training- and validation dataset
}
# - Finessing the annotation dataset for plotting
dat_anno_perf[, Label := paste0(Label, " = ", sprintf("%.4f",MAE*100), "%'")]
# - Adding an column to accommodate the facets
port.aggr_perf <- merge(port.aggr_perf, Facet_Label_Perf, by="PerfSpell_Resol")
port.aggr_perf[, Facet:=paste0('"', PerfSpell_Resol, ' (', sprintf("%.2f", Prior*100), '%)"')]
dat_anno_perf <- merge(dat_anno_perf, unique(subset(port.aggr_perf, select=c("PerfSpell_Resol", "Facet"))), by="PerfSpell_Resol")
# - Graphing parameters
chosenFont <- "Cambria"; dpi <- 340
col.v <- brewer.pal(9, "Set1")
label.v <- c("a_Full"=expression(italic(A)[t]*": Full set "*italic(D)),
"b_Train"=bquote(italic(B)[t]*": Training set "*italic(D)[italic(T)]~"("*.(round(datCredit_train[,.N]/1000))*"k)"),
"c_Valid"=bquote(italic(C)[t]*": Validation set "*italic(D)[italic(V)]~"("*.(round(datCredit_valid[,.N]/1000))*"k)"))
# - Create graph
(g3 <- ggplot(port.aggr_perf, aes(x=timeVar, y=Prop)) + theme_minimal() +
labs(x=bquote("Performing spell cohorts (ccyymm): entry time "*italic(t[e])), y=bquote("Resolution rate (%) of type "*~italic(kappa))) +
theme(text=element_text(family=chosenFont),legend.position = "bottom",
axis.text.x=element_text(angle=90), #legend.text=element_text(family=chosenFont),
strip.background=element_rect(fill="snow2", colour="snow2"),
strip.text=element_text(size=8, colour="gray50"), strip.text.y.right=element_text(angle=90)) +
# main line graph with overlaid points
geom_line(aes(colour=Sample, linetype=Sample)) +
geom_point(aes(colour=Sample, shape=Sample), size=1) +
# facets
facet_wrap(Facet~., labeller = label_parsed, scales = "free", nrow=length(resolPerf_levels), strip.position="right") +
#annotations
geom_text(data=dat_anno_perf, aes(x=x, y=y, hjust=hjust, vjust=vjust, label = Label), family=chosenFont, size=3, parse=T) +
# scale options
scale_colour_manual(name=bquote("Sample "*italic(bar(D))), values=col.v, labels=label.v) +
scale_shape_discrete(name=bquote("Sample "*italic(bar(D))), labels=label.v) + scale_linetype_discrete(name=bquote("Sample "*italic(bar(D))), labels=label.v) +
scale_y_continuous(breaks=pretty_breaks(), label=percent) +
scale_x_date(date_breaks=paste0(6, " month"), date_labels = "%b %Y"))
# - Save graph
ggsave(g3, file=paste0(genFigPath_Res_anc, "ResolutionRates_Perf_te_Subsample-", round(datCredit_smp[,.N]/1000),"k.png"), width=5000/(dpi*2.25), height=4000/(dpi*1.4), dpi=dpi, bg="white")
# - Cleanup
rm(dat_anno_perf, resolPerf_levels, chosenFont, col.v, label.v, colnames, datGraph_Perf, port.aggr_perf, port.aggr_perf2, maxDate, minDate, Facet_Label_Perf)
# Checking the proportions of the subsampled dataset and creating the corresponding faceting labels
(Facet_Label_Perf <- datCredit_smp[timeVar==timeVar_Perf_Max, get(resolPerf_stop)] %>% table() %>% prop.table() %>% data.table()) # Saving these proportions as they are used in the facets
colnames(Facet_Label_Perf) <- c("PerfSpell_Resol_Stop", "Prior") # Renaming the columns
# - Subsetting the main long dataset to only include the necessary variables for performance spells
datGraph_Perf <- datGraph %>% subset (!is.na(ClusVar_Perf), select=c("ClusVar_Perf", "timeVar", "timeVar_Perf_Max", resolPerf_stop, "Sample"))
colnames(datGraph_Perf) <- c("ClusVar_Perf", "timeVar", "timeVar_Perf_Max", "PerfSpell_Resol_Stop", "Sample")
# - Setting some aggregation parameters, purely to facilitate graphing aesthetics
StartDte <- min(datCredit_smp$timeVar, na.rm=T)
EndDte <- max(datCredit_smp$timeVar, na.rm=T)
maxDate <- EndDte %m-% months(1)# A post-hoc filter, used for graphing purposes - left as the end of the sampling window
minDate <- StartDte # %m+% months(1) # A post-hoc filter, used for graphing purposes - set as one month after the sampling window
# - Aggregate to monthly level and observe up to given point
port.aggr_perf <- merge(datGraph_Perf[timeVar==timeVar_Perf_Max, list(Sum_Total = .N), by=list(Sample,timeVar)],
datGraph_Perf[timeVar==timeVar_Perf_Max, list(Sum_Resol = .N), by=list(Sample,timeVar,PerfSpell_Resol_Stop)],
by=c("Sample", "timeVar"))[timeVar >= minDate & timeVar <= maxDate,]
port.aggr_perf[, Prop := Sum_Resol/Sum_Total]
# - Calculate MAE over time by sample, by performance event(s)
port.aggr_perf2 <- port.aggr_perf %>% pivot_wider(id_cols = c(timeVar), names_from = c(Sample, PerfSpell_Resol_Stop), values_from = Prop) %>% data.table()
# - Get the unique factors of the performance spell resolution type (used as facets)
resolPerf_levels <- unique(datCredit[!is.na(get(resolPerf_stop)), get(resolPerf_stop)])
# - Number of annotations "sets" to create
anno_n <- length(resolPerf_levels)
# - Initiating the annotation dataset
x_pos <- min(datCredit$timeVar) + round((max(datCredit$timeVar) - min(datCredit$timeVar))/2) # x-position fot the annotation
dat_anno_perf <- data.table(MAE = rep(0,anno_n*4),
Mean_EventRate = rep(0, anno_n*4),
stdError_EventRate = rep(0, anno_n*4),
margin_EventRate = rep(0, anno_n*4),
PerfSpell_Resol_Stop = unlist(lapply(resolPerf_levels, function(x){rep(x,4)})),
Dataset = rep(c("A-B","A-C","B-C", "B"), anno_n),
Label = rep(c(paste0("'MAE between '*italic(A[t])*' and '*italic(B[t])*'"),
paste0("'MAE between '*italic(A[t])*' and '*italic(C[t])*'"),
paste0("'MAE between '*italic(B[t])*' and '*italic(C[t])*'"),
paste0("'TTC-mean '*E(italic(B[t]))*'")), anno_n),
x = rep(x_pos,anno_n*4),
y = rep(Inf, anno_n*3), # c(c(0.48,0.45,0.42,0.38),c(0.65,0.62,0.59,0.55)),
vjust = rep(c(1,2,3, 4), anno_n),
hjust=rep(0.5, anno_n*4))
# - Getting the column names to help compute the MAEs
colnames <- colnames(port.aggr_perf2)
# - Populating the annotation dataset
for (i in 1:anno_n){
dat_anno_perf[i*4-3, MAE := mean(abs(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("a_Full_", resolPerf_levels[i])])[[1]] - subset(port.aggr_perf2, select=colnames[colnames %in% paste0("b_Train_", resolPerf_levels[i])])[[1]]), na.rm = T)] # MAE between the full- and training dataset
dat_anno_perf[i*4-2, MAE := mean(abs(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("a_Full_", resolPerf_levels[i])])[[1]] - subset(port.aggr_perf2, select=colnames[colnames %in% paste0("c_Valid_", resolPerf_levels[i])])[[1]]), na.rm = T)] # MAE between the full- and validation dataset
dat_anno_perf[i*4-1, MAE := mean(abs(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("b_Train_", resolPerf_levels[i])])[[1]] - subset(port.aggr_perf2, select=colnames[colnames %in% paste0("c_Valid_", resolPerf_levels[i])])[[1]]), na.rm = T)] # MAE between the training- and validation dataset
dat_anno_perf[i*4,   mean_EventRate := mean(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("b_Train_", resolPerf_levels[i])])[[1]], na.rm=T)]
dat_anno_perf[i*4,   stdError_EventRate := sd(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("b_Train_", resolPerf_levels[i])])[[1]], na.rm=T)/ sqrt(length(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("b_Train_", resolPerf_levels[i])])[[1]]))]
}
# - Finessing the annotation dataset for plotting
ind <- seq(from=4, to=4*anno_n, by=4)
dat_anno_perf[ind, margin_EventRate := qnorm(1-(1-confLevel)/2) * stdError_EventRate]
dat_anno_perf[ind, Label := paste0(Label, " = ", sprintf("%.2f", mean_EventRate*100) , "% +-", sprintf("%.3f", margin_EventRate*100), "%'")]
dat_anno_perf[seq(from=1, to=4*anno_n)[!(seq(from=1, to=4*anno_n) %in% ind)], Label := paste0(Label, " = ", sprintf("%.4f",MAE*100), "%'")]
# - Adding an column to accommodate the facets
port.aggr_perf <- merge(port.aggr_perf, Facet_Label_Perf, by="PerfSpell_Resol_Stop")
port.aggr_perf[, Facet:=paste0('"', PerfSpell_Resol_Stop, ' (', sprintf("%.2f", Prior*100), '%)"')]
dat_anno_perf <- merge(dat_anno_perf, unique(subset(port.aggr_perf, select=c("PerfSpell_Resol_Stop", "Facet"))), by="PerfSpell_Resol_Stop")
# - Graphing parameters
chosenFont <- "Cambria"; dpi <- 340
col.v <- brewer.pal(9, "Set1")
label.v <- c("a_Full"=expression(italic(A)[t]*": Full set "*italic(D)),
"b_Train"=bquote(italic(B)[t]*": Training set "*italic(D)[italic(T)]~"("*.(round(datCredit_train[,.N]/1000))*"k)"),
"c_Valid"=bquote(italic(C)[t]*": Validation set "*italic(D)[italic(V)]~"("*.(round(datCredit_valid[,.N]/1000))*"k)"))
# - Create graph
(g5 <- ggplot(port.aggr_perf, aes(x=timeVar, y=Prop)) + theme_minimal() +
labs(x=bquote("Performing spell cohorts (ccyymm): stop time "*italic(t[s])), y=bquote("Resolution rate (%) of type "*italic(kappa))) +
theme(text=element_text(family=chosenFont),legend.position = "bottom",
axis.text.x=element_text(angle=90), #legend.text=element_text(family=chosenFont),
strip.background=element_rect(fill="snow2", colour="snow2"),
strip.text=element_text(size=8, colour="gray50"), strip.text.y.right=element_text(angle=90)) +
# main line graph with overlaid points
geom_line(aes(colour=Sample, linetype=Sample)) +
geom_point(aes(colour=Sample, shape=Sample), size=1) +
# facets
facet_wrap(Facet~., labeller = label_parsed, scales = "free", nrow=length(resolPerf_levels), strip.position="right") +
#annotations
geom_text(data=dat_anno_perf, aes(x=x, y=y, hjust=hjust, label = Label), family=chosenFont, size=3, parse=T) +
# scale options
scale_colour_manual(name=bquote("Sample "*italic(bar(D))), values=col.v, labels=label.v) +
scale_shape_discrete(name=bquote("Sample "*italic(bar(D))), labels=label.v) + scale_linetype_discrete(name=bquote("Sample "*italic(bar(D))), labels=label.v) +
scale_y_continuous(breaks=pretty_breaks(), label=percent) +
scale_x_date(date_breaks=paste0(6, " month"), date_labels = "%b %Y"))
# - Save graph
ggsave(g5, file=paste0(genFigPath_Res_anc, "ResolutionRates_Perf_ts_Subsample-", round(datCredit_smp[,.N]/1000),"k.png"), width=5000/(dpi*2.25), height=4000/(dpi*1.4), dpi=dpi, bg="white")
dat_anno_perf <- data.table(MAE = rep(0,anno_n*4),
Mean_EventRate = rep(0, anno_n*4),
stdError_EventRate = rep(0, anno_n*4),
margin_EventRate = rep(0, anno_n*4),
PerfSpell_Resol_Stop = unlist(lapply(resolPerf_levels, function(x){rep(x,4)})),
Dataset = rep(c("A-B","A-C","B-C", "B"), anno_n),
Label = rep(c(paste0("'MAE between '*italic(A[t])*' and '*italic(B[t])*'"),
paste0("'MAE between '*italic(A[t])*' and '*italic(C[t])*'"),
paste0("'MAE between '*italic(B[t])*' and '*italic(C[t])*'"),
paste0("'TTC-mean '*E(italic(B[t]))*'")), anno_n),
x = rep(x_pos,anno_n*4),
y = rep(Inf, anno_n*4), # c(c(0.48,0.45,0.42,0.38),c(0.65,0.62,0.59,0.55)),
vjust = rep(c(1,2,3, 4), anno_n),
hjust=rep(0.5, anno_n*4))
# - Getting the column names to help compute the MAEs
colnames <- colnames(port.aggr_perf2)
# - Populating the annotation dataset
for (i in 1:anno_n){
dat_anno_perf[i*4-3, MAE := mean(abs(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("a_Full_", resolPerf_levels[i])])[[1]] - subset(port.aggr_perf2, select=colnames[colnames %in% paste0("b_Train_", resolPerf_levels[i])])[[1]]), na.rm = T)] # MAE between the full- and training dataset
dat_anno_perf[i*4-2, MAE := mean(abs(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("a_Full_", resolPerf_levels[i])])[[1]] - subset(port.aggr_perf2, select=colnames[colnames %in% paste0("c_Valid_", resolPerf_levels[i])])[[1]]), na.rm = T)] # MAE between the full- and validation dataset
dat_anno_perf[i*4-1, MAE := mean(abs(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("b_Train_", resolPerf_levels[i])])[[1]] - subset(port.aggr_perf2, select=colnames[colnames %in% paste0("c_Valid_", resolPerf_levels[i])])[[1]]), na.rm = T)] # MAE between the training- and validation dataset
dat_anno_perf[i*4,   mean_EventRate := mean(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("b_Train_", resolPerf_levels[i])])[[1]], na.rm=T)]
dat_anno_perf[i*4,   stdError_EventRate := sd(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("b_Train_", resolPerf_levels[i])])[[1]], na.rm=T)/ sqrt(length(subset(port.aggr_perf2, select=colnames[colnames %in% paste0("b_Train_", resolPerf_levels[i])])[[1]]))]
}
# - Finessing the annotation dataset for plotting
ind <- seq(from=4, to=4*anno_n, by=4)
dat_anno_perf[ind, margin_EventRate := qnorm(1-(1-confLevel)/2) * stdError_EventRate]
dat_anno_perf[ind, Label := paste0(Label, " = ", sprintf("%.2f", mean_EventRate*100) , "% +-", sprintf("%.3f", margin_EventRate*100), "%'")]
dat_anno_perf[seq(from=1, to=4*anno_n)[!(seq(from=1, to=4*anno_n) %in% ind)], Label := paste0(Label, " = ", sprintf("%.4f",MAE*100), "%'")]
# - Adding an column to accommodate the facets
dat_anno_perf <- merge(dat_anno_perf, unique(subset(port.aggr_perf, select=c("PerfSpell_Resol_Stop", "Facet"))), by="PerfSpell_Resol_Stop")
# - Graphing parameters
chosenFont <- "Cambria"; dpi <- 340
col.v <- brewer.pal(9, "Set1")
label.v <- c("a_Full"=expression(italic(A)[t]*": Full set "*italic(D)),
"b_Train"=bquote(italic(B)[t]*": Training set "*italic(D)[italic(T)]~"("*.(round(datCredit_train[,.N]/1000))*"k)"),
"c_Valid"=bquote(italic(C)[t]*": Validation set "*italic(D)[italic(V)]~"("*.(round(datCredit_valid[,.N]/1000))*"k)"))
# - Create graph
(g5 <- ggplot(port.aggr_perf, aes(x=timeVar, y=Prop)) + theme_minimal() +
labs(x=bquote("Performing spell cohorts (ccyymm): stop time "*italic(t[s])), y=bquote("Resolution rate (%) of type "*italic(kappa))) +
theme(text=element_text(family=chosenFont),legend.position = "bottom",
axis.text.x=element_text(angle=90), #legend.text=element_text(family=chosenFont),
strip.background=element_rect(fill="snow2", colour="snow2"),
strip.text=element_text(size=8, colour="gray50"), strip.text.y.right=element_text(angle=90)) +
# main line graph with overlaid points
geom_line(aes(colour=Sample, linetype=Sample)) +
geom_point(aes(colour=Sample, shape=Sample), size=1) +
# facets
facet_wrap(Facet~., labeller = label_parsed, scales = "free", nrow=length(resolPerf_levels), strip.position="right") +
#annotations
geom_text(data=dat_anno_perf, aes(x=x, y=y, hjust=hjust, label = Label), family=chosenFont, size=3, parse=T) +
# scale options
scale_colour_manual(name=bquote("Sample "*italic(bar(D))), values=col.v, labels=label.v) +
scale_shape_discrete(name=bquote("Sample "*italic(bar(D))), labels=label.v) + scale_linetype_discrete(name=bquote("Sample "*italic(bar(D))), labels=label.v) +
scale_y_continuous(breaks=pretty_breaks(), label=percent) +
scale_x_date(date_breaks=paste0(6, " month"), date_labels = "%b %Y"))
# - Create graph
(g5 <- ggplot(port.aggr_perf, aes(x=timeVar, y=Prop)) + theme_minimal() +
labs(x=bquote("Performing spell cohorts (ccyymm): stop time "*italic(t[s])), y=bquote("Resolution rate (%) of type "*italic(kappa))) +
theme(text=element_text(family=chosenFont),legend.position = "bottom",
axis.text.x=element_text(angle=90), #legend.text=element_text(family=chosenFont),
strip.background=element_rect(fill="snow2", colour="snow2"),
strip.text=element_text(size=8, colour="gray50"), strip.text.y.right=element_text(angle=90)) +
# main line graph with overlaid points
geom_line(aes(colour=Sample, linetype=Sample)) +
geom_point(aes(colour=Sample, shape=Sample), size=1) +
# facets
facet_wrap(Facet~., labeller = label_parsed, scales = "free", nrow=length(resolPerf_levels), strip.position="right") +
#annotations
geom_text(data=dat_anno_perf, aes(x=x, y=y, hjust=hjust, vjust=vjust, label = Label), family=chosenFont, size=3, parse=T) +
# scale options
scale_colour_manual(name=bquote("Sample "*italic(bar(D))), values=col.v, labels=label.v) +
scale_shape_discrete(name=bquote("Sample "*italic(bar(D))), labels=label.v) + scale_linetype_discrete(name=bquote("Sample "*italic(bar(D))), labels=label.v) +
scale_y_continuous(breaks=pretty_breaks(), label=percent) +
scale_x_date(date_breaks=paste0(6, " month"), date_labels = "%b %Y"))
# - Save graph
ggsave(g5, file=paste0(genFigPath_Res_anc, "ResolutionRates_Perf_ts_Subsample-", round(datCredit_smp[,.N]/1000),"k.png"), width=5000/(dpi*2.25), height=4000/(dpi*1.4), dpi=dpi, bg="white")
# - Cleanup
rm(dat_anno_perf, resolPerf_levels, ind, chosenFont, col.v, label.v, colnames, datGraph_Perf, port.aggr_perf, port.aggr_perf2, maxDate, minDate, Facet_Label_Perf)
# ------ 9. Graphing default spell resolution rates over time given resampled sets | Spell exit time (t_s)
# - Check representatives | dataset-level proportions should be similar
datCredit[timeVar==timeVar_Def_Max, get(resolDef_stop)] %>% table() %>% prop.table()
datCredit_train[timeVar==timeVar_Def_Max, get(resolDef_stop)] %>% table() %>% prop.table()
datCredit_valid[timeVar==timeVar_Def_Max, get(resolDef_stop)] %>% table() %>% prop.table()
# Checking the proportions of the subsampled dataset and creating the corresponding faceting labels
(Facet_Label_Def <- datCredit_smp[timeVar==timeVar_Def_Max, get(resolDef_stop)] %>% table() %>% prop.table() %>% data.table()) # Saving these proportions as they are used in the facets
colnames(Facet_Label_Def) <- c("DefSpell_Resol_Stop", "Prior") # Renaming the columns
# - Subsetting the main long dataset to only include the necessary variables for performance spells
datGraph_Def <- datGraph %>% subset(!is.na(ClusVar_Def), select=c("ClusVar_Def", "timeVar", "timeVar_Def_Max", resolDef_stop, "Sample"))
colnames(datGraph_Def) <- c("ClusVar_Def", "timeVar", "timeVar_Def_Max", "DefSpell_Resol_Stop", "Sample")
# - Setting some aggregation parameters, purely to facilitate graphing aesthetics
StartDte <- min(datCredit_smp$timeVar, na.rm=T)
EndDte <- max(datCredit_smp$timeVar, na.rm=T)
maxDate <- EndDte # A post-hoc filter, used for graphing purposes - left as the end of the sampling window
minDate <- StartDte # %m+% months(1) # A post-hoc filter, used for graphing purposes - set as one month after the sampling window
# - Aggregate to monthly level and observe up to given point
port.aggr_def <- merge(datGraph_Def[timeVar==timeVar_Def_Max, list(Sum_Total = .N), by=list(Sample,timeVar)],
datGraph_Def[timeVar==timeVar_Def_Max, list(Sum_Resol = .N), by=list(Sample,timeVar,DefSpell_Resol_Stop)],
by=c("Sample", "timeVar"))[timeVar >= minDate & timeVar <= maxDate,]
port.aggr_def[, Prop := Sum_Resol/Sum_Total]
# - Calculate MAE over time by sample, by competing event(s)
port.aggr_def2 <- port.aggr_def %>% pivot_wider(id_cols = c(timeVar), names_from = c(Sample, DefSpell_Resol_Stop), values_from = Prop) %>% as.data.table()
# - Get the unique factors of the default spell resolution type (used as facets)
resolDef_levels <- unique(datCredit[!is.na(get(resolDef_stop)), get(resolDef_stop)])
# - Number of annotations "sets" to create
anno_n <- length(resolDef_levels)
# - Initiating the annotation dataset
x_pos <- min(datCredit$timeVar) + round((max(datCredit$timeVar) - min(datCredit$timeVar))/2) + months(16)# x-position fot the annotation
dat_anno_def <- data.table(MAE = rep(0,anno_n*4),
Mean_EventRate = rep(0, anno_n*4),
stdError_EventRate = rep(0, anno_n*4),
margin_EventRate = rep(0, anno_n*4),
DefSpell_Resol_Stop = unlist(lapply(resolDef_levels, function(x){rep(x,4)})),
Dataset = rep(c("A-B","A-C","B-C", "B"), anno_n),
Label = rep(c(paste0("'MAE between '*italic(A[t])*' and '*italic(B[t])*'"),
paste0("'MAE between '*italic(A[t])*' and '*italic(C[t])*'"),
paste0("'MAE between '*italic(B[t])*' and '*italic(C[t])*'"),
paste0("'TTC-mean '*E(italic(B[t]))*'")), anno_n),
x = rep(x_pos,anno_n*4),
y =   rep(Inf, anno_n*4), # c(c(0.5,0.48,0.46,0.42),c(0.64,0.62,0.60,0.56)),
vjust = rep(c(1,2,3, 4), anno_n),
hjust=rep(0.5, anno_n*4))
# - Getting the column names to help compute the MAEs
colnames <- colnames(port.aggr_def2)
# - Populating the annotation dataset
for (i in 1:anno_n){
dat_anno_def[i*4-3, MAE := mean(abs(subset(port.aggr_def2, select=colnames[colnames %in% paste0("a_Full_", resolDef_levels[i])])[[1]] - subset(port.aggr_def2, select=colnames[colnames %in% paste0("b_Train_", resolDef_levels[i])])[[1]]), na.rm = T)] # MAE between the full- and training dataset
dat_anno_def[i*4-2, MAE := mean(abs(subset(port.aggr_def2, select=colnames[colnames %in% paste0("a_Full_", resolDef_levels[i])])[[1]] - subset(port.aggr_def2, select=colnames[colnames %in% paste0("c_Valid_", resolDef_levels[i])])[[1]]), na.rm = T)] # MAE between the full- and validation dataset
dat_anno_def[i*4-1, MAE := mean(abs(subset(port.aggr_def2, select=colnames[colnames %in% paste0("b_Train_", resolDef_levels[i])])[[1]] - subset(port.aggr_def2, select=colnames[colnames %in% paste0("c_Valid_", resolDef_levels[i])])[[1]]), na.rm = T)] # MAE between the training- and validation dataset
dat_anno_def[i*4,   mean_EventRate := mean(subset(port.aggr_def2, select=colnames[colnames %in% paste0("b_Train_", resolDef_levels[i])])[[1]], na.rm=T)]
dat_anno_def[i*4,   stdError_EventRate := sd(subset(port.aggr_def2, select=colnames[colnames %in% paste0("b_Train_", resolDef_levels[i])])[[1]], na.rm=T)/ sqrt(length(subset(port.aggr_def2, select=colnames[colnames %in% paste0("b_Train_", resolDef_levels[i])])[[1]]))]
}
# - Finessing the annotation dataset for plotting
ind <- seq(from=4, to=4*anno_n, by=4)
dat_anno_def[ind, margin_EventRate := qnorm(1-(1-confLevel)/2) * stdError_EventRate]
dat_anno_def[ind, Label := paste0(Label, " = ", sprintf("%.2f", mean_EventRate*100) , "% +-", sprintf("%.3f", margin_EventRate*100), "%'")]
dat_anno_def[seq(from=1, to=4*anno_n)[!(seq(from=1, to=4*anno_n) %in% ind)], Label := paste0(Label, " = ", sprintf("%.4f",MAE*100), "%'")]
# - Adding an column to accommodate the facets
port.aggr_def <- merge(port.aggr_def, Facet_Label_Def, by="DefSpell_Resol_Stop")
port.aggr_def[, Facet:=paste0('"', DefSpell_Resol_Stop, ' (', sprintf("%.2f", Prior*100), '%)"')]
dat_anno_def <- merge(dat_anno_def, unique(subset(port.aggr_def, select=c("DefSpell_Resol_Stop", "Facet"))), by="DefSpell_Resol_Stop")
# - Graphing parameters
chosenFont <- "Cambria"; dpi <- 340
col.v <- brewer.pal(9, "Set1")
label.v <- c("a_Full"=expression(italic(A)[t]*": Full set "*italic(D)),
"b_Train"=bquote(italic(B)[t]*": Training set "*italic(D)[italic(T)]~"("*.(round(datCredit_train[,.N]/1000))*"k)"),
"c_Valid"=bquote(italic(C)[t]*": Validation set "*italic(D)[italic(V)]~"("*.(round(datCredit_valid[,.N]/1000))*"k)"))
# - Create graph
(g6 <- ggplot(port.aggr_def, aes(x=timeVar, y=Prop)) + theme_minimal() +
labs(x=bquote("Default spell cohorts (ccyymm): stop time "*italic(t[s])), y=bquote("Resolution rate (%) of type "*italic(kappa))) +
theme(text=element_text(family=chosenFont),legend.position = "bottom",
axis.text.x=element_text(angle=90), #legend.text=element_text(family=chosenFont),
strip.background=element_rect(fill="snow2", colour="snow2"),
strip.text=element_text(size=8, colour="gray50"), strip.text.y.right=element_text(angle=90)) +
# main line graph with overlaid points
geom_line(aes(colour=Sample, linetype=Sample)) +
geom_point(aes(colour=Sample, shape=Sample), size=1) +
# facets
facet_wrap(Facet~., labeller = label_parsed, scales = "free", nrow=length(resolDef_levels), strip.position="right") +
#annotations
geom_text(data=dat_anno_def, aes(x=x, y=y, hjust=hjust, vjust=vjust, label = Label), family=chosenFont, size=3, parse=T) +
# scale options
scale_colour_manual(name=bquote("Sample "*italic(bar(D))), values=col.v, labels=label.v) +
scale_shape_discrete(name=bquote("Sample "*italic(bar(D))), labels=label.v) + scale_linetype_discrete(name=bquote("Sample "*italic(bar(D))), labels=label.v) +
scale_y_continuous(breaks=pretty_breaks(), label=percent) +
scale_x_date(date_breaks=paste0(6, " month"), date_labels = "%b %Y"))
# - Save graph
ggsave(g6, file=paste0(genFigPath_Res_anc, "ResolutionRates_Def_ts_Subsample-", round(datCredit_smp[,.N]/1000),"k.png"), width=5000/(dpi*2.25), height=4000/(dpi*1.4), dpi=dpi, bg="white")
rm(list=ls())
# =================================== SETUP =============================================
# Setting up R environment, parameters, and function definitions
# ---------------------------------------------------------------------------------------
# PROJECT TITLE: Default survival modelling
# SCRIPT AUTHOR(S): Dr Arno Botha, Roelinde Bester, Marcel Muller
# DESCRIPTION:
# This script installs and loads various libraries and packages, compiles all
# custom functions, and set requisite parameters.
# ---------------------------------------------------------------------------------------
# -- Inputs:
#   - DelinqM.R | Delinquency measures and related functions
# =======================================================================================
# ================ 0. Library setup
# ------ Install and load packages
# - data access and big data management
require(haven) # for SAS imports
require(ETLUtils)
require(ffbase)
require(ff)
tempPath <- "C:/TempData"; options("fftempdir"=tempPath)
# for data wrangling
require(tidyr)
require(dplyr)
require(data.table)
require(lubridate)
require(readr)
require(bit64) # for very big numeric values
require(stringr) # common string operations, e.g, str_pad
require(purrr) # mapping functions from tidyverse in working with matrices, lists
# for advanced looping functionality in simulation tasks
require(doBy)
require(foreach)
require(doParallel)
# for analyses
require(Hmisc)
require(moments) # for using skewness() function
require(regclass) # for VIF
# for modelling
require(survival) # for survival modelling
require(zoo)
require(car)
require(survivalROC) # for time-dependent ROC-analysis from Heagerty et al.
#require(survAUC) # for time-dependent ROC-analysis (alternative from Potapov et al.)
#require(tdROC) # for time-dependent ROC-analysis ([outdated?] alternative from Li et al.)
#require(timeROC) # for time-dependent ROC-analysis ([outdated?] alternative from Blanche)
require(pROC); require(ROCR) # both for cross-sectional ROC-analysis (main:pROC)
require(discSurv)
require(MASS)
#for plots
require(ggplot2)
require(ggpp) # Extensions to ggplot2, particularly geom_table
require(scales)
require(ggthemes)
require(RColorBrewer)
require(extrafont) #remotes::install_version("Rttf2pt1", version = "1.3.8"); Sys.setenv(R_GSCMD="C:/Program Files/gs/gs9.55.0/bin/gswin32c.exe"); font_import(); loadfonts(); loadfonts(device="win")
require(survminer)
require(gridExtra)
require(corrplot)
require(Metrics)
# ================ 1. Parametrisation
# - general R options
options(scipen=999) # Suppress showing scientific notation
# - Parameters used in calculating delinquency measures
sc.Thres <- 0.9; # repayment ratio - g1
d <- 3 # default threshold for g0/g1-measures of delinquency (payments in arrears)
k <- 6 # Probation period
# --- User specific paths
# - Getting the username of the current active user
Username <- Sys.getenv("USERNAME")
# - Setting the paths conditional on the current active user
if (Username == "WRQ"){ ### - Paths for AB
# Custom path where R-scripts are saved
path_cust <- "C:/Users/WRQ/OneDrive - FRG/Analytix/Research/Default Survival Modelling/Scripts/"
# Common path for storing important R-objects as back-up
genObjPath <- "C:/Users/WRQ/OneDrive - FRG/Analytix/Research/Default Survival Modelling/Objects/"
genObjPath_Res <- "C:/Users/WRQ/OneDrive - FRG/Default Survival Modelling/Objects/Resampling Schemes/" # Excel sheets for resampling tests
# Common path for saving important analytics (e.g., sampling)
genFigPath <- "C:/Users/WRQ/OneDrive - FRG/Analytix/Research/Default Survival Modelling/Figures/" # General folder path
genFigPath_CumHaz <- "C:/Users/WRQ/OneDrive - FRG/Analytix/Research/Default Survival Modelling/Figures/Baseline Hazard Comparison/" # Figures of baseline (cumulative) hazard comparison
genFigPath_Res <- "C:/Users/WRQ/OneDrive - FRG/Analytix/Research/Default Survival Modelling/Figures/Resampling Comparison/Main/" # Figures of resampling tests
genFigPath_Res_anc <- "C:/Users/WRQ/OneDrive - FRG/Analytix/Research/Default Survival Modelling/Figures/Resampling Comparison/Exploratory/" # Ancillary figures of resampling tests
genFigPath_ass <- "C:/Users/WRQ/OneDrive - FRG/Analytix/Research/Default Survival Modelling/Figures/Modelling Assumptions/" # Modelling assumptions path
} else if (Username == "R5532132"){ ### - Paths for MM
# Custom path where R-scripts are saved
path_cust <- "C:/Users/R5532132/OneDrive - FRG/Default Survival Modelling/Scripts/"
# Common path for storing important R-objects as back-up
genObjPath <- "C:/Users/R5532132/OneDrive - FRG/Default Survival Modelling/Objects/" # General objects"
genObjPath_Res <- "C:/Users/R5532132/OneDrive - FRG/Default Survival Modelling/Objects/Resampling Schemes/" # Excel sheets for resampling tests
# Common path for saving important analytics (e.g., sampling)
genFigPath <- "C:/Users/R5532132/OneDrive - FRG/Default Survival Modelling/Figures" # General folder path
genFigPath_CumHaz <- "C:/Users/R5532132/OneDrive - FRG/Default Survival Modelling/Figures/Baseline Hazard Comparison/" # Figures of baseline (cumulative) hazard comparison
genFigPath_Res <- "C:/Users/R5532132/OneDrive - FRG/Default Survival Modelling/Figures/Resampling Comparison/Main/" # Figures of resampling tests
genFigPath_Res_anc <- "C:/Users/R5532132/OneDrive - FRG/Default Survival Modelling/Figures/Resampling Comparison/Exploratory/" # Ancillary figures of resampling tests
genFigPath_ass <- "C:/Users/R5532132/OneDrive - FRG/Default Survival Modelling/Figures/Modelling Assumptions/" # Modelling assumptions path
} else { ### - If username not found in if statements, execution stops
stop("User-specific paths not set for current user: ", Username, ". Please fix in setup script (0.Setup.R) before continuing.")
}
# --- General paths
# - Common path for saving big data objects
genPath <- "C:/Data/DefaultSurv_Data/"
# - Common path for importing raw data
genRawPath <- "C:/Data/"
# ================ 2. Custom functions
# ------ Custom function definitions
# - Load all custom functions defined in a separate R-script
source(paste0(path_cust,"0a(i).CustomFunctions.R"))
# - True End procedure functions defined in a separate R-script
source(paste0(path_cust,"0a(ii).TruEnd.R"))
# - Compile Delinquency Calculation Functions (CD, MD/DoD)
source(paste0(path_cust,'0a(iii).DelinqM.R'))
# - Survival functions
source(paste0(path_cust,'0a(iv).SurvFunc.R'))
# ------ 1. Preliminaries
# --- Load in Dataset
if (!exists('datCredit_real')) unpack.ffdf(paste0(genPath,"creditdata_final4"), tempPath)
# --- Some feature engineering
# - Loan ever defaulted
# Creating a default spell "maximum" date as to facilitate subsequent feature engineering
datCredit_real[!is.na(DefSpell_Key), DefSpell_Max_Date := max(Date, na.rm=T), by=list(DefSpell_Key)]
datCredit_real[is.na(DefSpell_Key), DefSpell_Max_Date:= NA]
# - Creating a curing indicator for default spells (enables graphing of curing events in default spells)
datCredit_real[, Cured_Ind := ifelse(!is.na(DefSpell_Key) & DefSpellResol_Type_Hist=="Cured" & Date==DefSpell_Max_Date,1,0)] # | Reduce conditions to only the second and third (check feasibility)
# - Creating new spell resolution types
# Performance spells
datCredit_real <- datCredit_real %>% mutate(PerfSpellResol_Type_Hist2 = case_when(PerfSpellResol_Type_Hist=="Defaulted" ~ "Defaulted",
PerfSpellResol_Type_Hist=="Censored" ~ "Censored",
PerfSpellResol_Type_Hist %in% c("Settled", "Paid-up", "Written-off") ~ "Settled & Other",
TRUE ~ NA))
datCredit_real <- datCredit_real %>% mutate(PerfSpellResol_Type_Hist3 = case_when(PerfSpellResol_Type_Hist=="Defaulted" ~ "Defaulted",
PerfSpellResol_Type_Hist %in% c("Censored", "Settled", "Paid-up", "Written-off") ~ "Other",
TRUE ~ NA))
# Sanity check - Should be TRUE
datCredit_real[is.na(PerfSpell_Key),.N] == datCredit_real[is.na(PerfSpellResol_Type_Hist2),.N] # TRUE, field created successfully
datCredit_real[is.na(PerfSpell_Key),.N] == datCredit_real[is.na(PerfSpellResol_Type_Hist3),.N] # TRUE, field created successfully
# - Creating new default spell resolution types
datCredit_real <- datCredit_real %>% mutate(DefSpellResol_Type_Hist2 = case_when(DefSpellResol_Type_Hist=="WOFF" ~ "WOFF",
DefSpellResol_Type_Hist %in% c("Cured", "Censored") ~ "Other",
TRUE ~ NA))
# Sanity check - Should be TRUE
datCredit_real[is.na(DefSpell_Key),.N] == datCredit_real[is.na(DefSpellResol_Type_Hist2),.N] # TRUE, field created successfully
# --- Identifying single observation default spells as they are not taken into account directly through the subsampling/ resampling scheme
datCredit_real[, DefSpell_Exc := F] # Creating a variable for identifying these observations
datCredit_real[DefSpell_Counter==1 & Date==DefSpell_Max_Date, DefSpell_Exc := T] # Identifying FALSE default spells
# - Checking how many single-observation default spells exist and assessing their impact
(check.1 <- datCredit_real[DefSpell_Exc==T, .N] / datCredit_real[DefSpell_Counter==1,.N])
cat(sprintf("%.4f", check.1), "% (", datCredit_real[DefSpell_Exc==T, .N], " of ", datCredit_real[DefSpell_Counter==1,.N], ")", "of default spells are to be excluded and are indirectly taken in to account via the subsampling/ resampling scheme.")
# --- Some parameters
# - Confidence interval parameter
confLevel <- 0.95
# - Field names
targetVar <- c("DefaultStatus1_lead_12_max") # Field name of the main target (i.e., the 12-month default rate)
CurStatus <- "DefaultStatus1"
resolPerf <- "PerfSpellResol_Type_Hist2" # Field name of performance spell resolution types - first level should be the target event (default)
resolDef <- "DefSpellResol_Type_Hist" # Field name of default spell resolution types
excDef <- "DefSpell_Exc" # Field for identifying single-observation default spells (they are indirectly excluded from the resampling scheme)
clusVar <- "LoanID" # Field name of unique account identifier
clusVar_Perf <- "PerfSpell_Key" # Field name of unique performance spell identifier
clusVar_Def <- "DefSpell_Key" # Field name of unique default spell identifier
timeVar <- "Date" # Field name of time variable
counter <- "Counter" # Field name of counter for loan observations
perfCounter <- "PerfSpell_Counter" # Field name of counter for performance spell observations
defCounter <- "DefSpell_Counter" # Field name of counter for default spell observations
# - Optional field names
# - Optional field names
stratifiers_Perf <- "PerfSpell_Max_Date" # c("PerfSpell_Max_Date", "PerfSpellResol_Type_Hist2") #First variable should be of type "date"
stratifiers_Def <- "DefSpell_Max_Date" # c("DefSpell_Max_Date", "DefSpellResol_Type_Hist")
resolPerf_stop <- "PerfSpellResol_Type_Hist3" # Field name for performance spell resolution rate; specific for the stopping time cohort | Assign [resolPerf] if not interested in controlling the resolution rate facet for stop dates
resolDef_stop <-  "DefSpellResol_Type_Hist2" # Field name for default spell resolution rate; specific for the stopping time cohort | Assign [resolDef] if not interested in controlling the resolution rate facet for stop dates
# Final Selection
selectionVar <- unique(c(clusVar, clusVar_Perf, clusVar_Def, timeVar, CurStatus, counter, perfCounter, defCounter, resolPerf, resolDef,
resolPerf_stop, resolDef_stop, excDef, stratifiers_Perf, stratifiers_Def, targetVar)) # Variables to subset
selectionVar <- selectionVar[!is.na(selectionVar)] # Facilitating cases where the variables are left unspecified (specifically for use of no stratifiers)
# - Subset given dataset accordingly; an efficiency enhancement
datCredit <- subset(datCredit_real, select=selectionVar)
# --- Some feature engineering
# - Spell level time variables
# - Max- and min date of each performance spell (used as a stratifier)
datCredit_real[!is.na(PerfSpell_Key), c("PerfSpell_Min_Time","PerfSpell_Max_Time") := as.list(range(Date, na.rm=TRUE)), by=list(PerfSpell_Key)]
datCredit_real[is.na(PerfSpell_Key), c("PerfSpell_Min_Time","PerfSpell_Max_Time") := as.list(c(NA,NA)), by=list(PerfSpell_Key)]
# Sanity check - Should be TRUE
datCredit_real[!is.na(PerfSpell_Key),.N] == datCredit_real[!is.na(PerfSpell_Max_Time)]
